{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from numpy import array\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from torch import tensor\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of recognized words you put in input\n",
    "nb_input = 100 #8414 max\n",
    "\n",
    "# Number of classe, constant\n",
    "nb_output = 6\n",
    "\n",
    "# Number of hidden layers\n",
    "nb_hidd_lay = 1\n",
    "hidden_size = 1\n",
    "\n",
    "# Learning rate\n",
    "lr = 0.005\n",
    "\n",
    "# Number of epochs\n",
    "nb_epochs = 5\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding in windows-1252, utf-8 generate error on some char\n",
    "file = codecs.open(\"train_all.label\", \"r+\",\"windows-1252\")\n",
    "train_data = []\n",
    "for line in file.readlines():\n",
    "    train_data.append(line)\n",
    "\n",
    "# Now test set\n",
    "file = codecs.open(\"TREC_test.label\", \"r+\",\"windows-1252\")\n",
    "test_data = []\n",
    "for line in file.readlines():\n",
    "    test_data.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatisation\n",
    "# Working on list_of_words\n",
    "# TODO: it doesn't work\n",
    "def lemm(phrase):\n",
    "    lemmer = WordNetLemmatizer()\n",
    "    lemmed = []\n",
    "    for word in phrase:\n",
    "        lemmed.append(lemmer.lemmatize(word, pos=\"v\"))\n",
    "    return lemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(questions) = 15452\n",
      "Exemples of questions:\n",
      "[['how', 'do', 'serfdom', 'develop', 'in', 'and', 'then', 'leave', 'russia', '?'], ['what', 'film', 'feature', 'the', 'character', 'popeye', 'doyle', '?']]\n",
      "\n",
      "And in the test set:\n",
      "len(questions_test) = 500\n",
      "Exemples of questions:\n",
      "[['how', 'far', 'be', 'it', 'from', 'denver', 'to', 'aspen', '?'], ['what', 'county', 'be', 'modesto', ',', 'california', 'in', '?']]\n"
     ]
    }
   ],
   "source": [
    "# Divided file into 2 list:\n",
    "# questions = list of questions \n",
    "# labels = list of labels\n",
    "\n",
    "questions = []\n",
    "labels = []\n",
    "\n",
    "# Black list\n",
    "regex = re.compile('[@_!#$%^&*()<>?/\\|}{~:]')\n",
    "\n",
    "(train_data[0]).split()[0]\n",
    "for string in train_data:\n",
    "    question_str = []\n",
    "    for x in lemm(string.split()[1:]):\n",
    "        question_str.append(x.lower())\n",
    "    labels.append(string.split()[0])\n",
    "    questions.append(question_str)\n",
    "print(\"len(questions) = \" + str(len(questions)))\n",
    "print(\"Exemples of questions:\")\n",
    "print(questions[:2])\n",
    "\n",
    "\n",
    "\n",
    "questions_test = []\n",
    "labels_test = []\n",
    "\n",
    "(test_data[0]).split()[0]\n",
    "for string in test_data:\n",
    "    question_str = []\n",
    "    for x in lemm(string.split()[1:]):\n",
    "        question_str.append(x.lower())\n",
    "    labels_test.append(string.split()[0])\n",
    "    questions_test.append(question_str)\n",
    "print()\n",
    "print(\"And in the test set:\")\n",
    "print(\"len(questions_test) = \" + str(len(questions_test)))\n",
    "print(\"Exemples of questions:\")\n",
    "print(questions_test[:2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to add tags begin and end to phrases list.\n",
    "# /!\\ \n",
    "# WARNING : this method need to be executed only ONE time.\n",
    "# /!\\\n",
    "def add_tag(question_list):\n",
    "    for i in range(0, len(question_list)):\n",
    "        if question_list[i][0] != '<bos>' :\n",
    "            question_list[i].insert(0, '<bos>')\n",
    "            question_list[i].append('<eos>')\n",
    "add_tag(questions)\n",
    "add_tag(questions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188317\n",
      "CPU times: user 24 ms, sys: 4 ms, total: 28 ms\n",
      "Wall time: 27.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Vocabulary of unique words\n",
    "data = []\n",
    "data.append('<unk>')\n",
    "for q in questions:\n",
    "    for word in q:\n",
    "        data.append(word)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scv = np.array(data)\n",
    "unik, counts = np.unique(scv,return_counts=True)\n",
    "vocabulary = {}\n",
    "for i in range(0, len(unik)):\n",
    "    vocabulary[unik[i]] = counts[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'falls': 7,\n",
       " 'territory': 9,\n",
       " 'database': 9,\n",
       " 'chickenpoxs': 3,\n",
       " 'nearest': 3,\n",
       " 'cinzano': 3,\n",
       " 'eidologist': 1,\n",
       " 'cholera': 3,\n",
       " 'registration': 2,\n",
       " 'switch': 2,\n",
       " 'smothers': 1,\n",
       " 'users': 2,\n",
       " 'treatments': 2,\n",
       " 'taj': 3,\n",
       " 'nanometer': 5,\n",
       " 'fig': 3,\n",
       " 'developmental': 5,\n",
       " 'shots': 5,\n",
       " 'yahoo': 12,\n",
       " 'god-sullen': 5,\n",
       " 'political': 6,\n",
       " 'cure': 1,\n",
       " 'depend': 4,\n",
       " 'hollywood': 18,\n",
       " 'hall': 8,\n",
       " 'accommodate': 1,\n",
       " 'mammal': 12,\n",
       " 'wisconsin': 4,\n",
       " 'cologne': 4,\n",
       " 'sugar': 5,\n",
       " 'highest': 87,\n",
       " 'multicultural': 1,\n",
       " 'rockin': 1,\n",
       " 'stat': 4,\n",
       " 'anka': 4,\n",
       " 'lou': 8,\n",
       " 'volleyball': 1,\n",
       " 'insure': 5,\n",
       " 'maya': 2,\n",
       " 'viagra': 4,\n",
       " 'inhabit': 5,\n",
       " 'definition': 44,\n",
       " 'al-farri': 5,\n",
       " 'determinism': 2,\n",
       " 'spray': 8,\n",
       " 'chairbound': 5,\n",
       " 'grade': 2,\n",
       " 'sensitive': 12,\n",
       " 'travels': 6,\n",
       " 'wonders': 7,\n",
       " 'active': 8,\n",
       " 'pitchers': 4,\n",
       " 'zodiacal': 7,\n",
       " 'slinky': 4,\n",
       " 'formula': 6,\n",
       " 'promoters': 5,\n",
       " 'must': 18,\n",
       " 'ash': 6,\n",
       " '9971': 3,\n",
       " 'basic': 1,\n",
       " 'airforce': 1,\n",
       " 'leg': 9,\n",
       " 'christopher': 9,\n",
       " 'rom': 1,\n",
       " 'theatrical': 1,\n",
       " 'long': 167,\n",
       " 'section': 3,\n",
       " 'bring': 16,\n",
       " 'entire': 5,\n",
       " 'smallest': 9,\n",
       " 'ringo': 5,\n",
       " 'samuel': 10,\n",
       " 'stall': 5,\n",
       " 'great': 56,\n",
       " 'pies': 1,\n",
       " 'wall': 33,\n",
       " 'fiesta': 3,\n",
       " 'symphony': 4,\n",
       " 'marino': 1,\n",
       " 'hillbillies': 1,\n",
       " 'puddle': 1,\n",
       " 'edessa': 2,\n",
       " 'whale': 6,\n",
       " 'shaken': 5,\n",
       " 'journalism': 4,\n",
       " 'doodle': 3,\n",
       " 'associaton': 4,\n",
       " 'premier': 8,\n",
       " 'competitor': 5,\n",
       " '...the': 4,\n",
       " 'match': 10,\n",
       " 'dumplings': 2,\n",
       " 'f': 9,\n",
       " 'tenths': 2,\n",
       " 'anniversary': 12,\n",
       " 'named': 1,\n",
       " 'clip': 9,\n",
       " 'stephen': 7,\n",
       " 'thalassemia': 9,\n",
       " 'falwell': 5,\n",
       " 'barton': 1,\n",
       " 'mall': 4,\n",
       " 'maris': 2,\n",
       " 'allan': 4,\n",
       " 'singer': 29,\n",
       " 'own': 51,\n",
       " 'competition': 6,\n",
       " 'grapes': 5,\n",
       " 'annual': 4,\n",
       " 'gift': 3,\n",
       " 'foreign': 1,\n",
       " 'threat': 2,\n",
       " 'popeye': 13,\n",
       " 'lobster': 9,\n",
       " 'arabian': 5,\n",
       " 'moby': 7,\n",
       " 'equinox': 4,\n",
       " 'heliologist': 3,\n",
       " 'hotel': 8,\n",
       " '1932': 5,\n",
       " 'parker': 3,\n",
       " 'leave': 38,\n",
       " 'colonel': 5,\n",
       " 'races': 8,\n",
       " 'napolean': 1,\n",
       " 'straight': 3,\n",
       " 'bee': 16,\n",
       " 'steam': 6,\n",
       " 'maryland': 8,\n",
       " 'cleopatra': 2,\n",
       " 'hooligans': 8,\n",
       " 'stadium': 10,\n",
       " 'battery': 16,\n",
       " 'members': 16,\n",
       " 'turret': 1,\n",
       " 'connecticut': 6,\n",
       " 'associates': 6,\n",
       " 'billion': 2,\n",
       " 'domesticate': 9,\n",
       " 'recruitment': 3,\n",
       " 'just': 17,\n",
       " 'spaghetti-o': 2,\n",
       " 'nile': 8,\n",
       " 'hesse': 4,\n",
       " 'dumont': 2,\n",
       " 'out': 109,\n",
       " 'masters': 5,\n",
       " 'rev.': 5,\n",
       " 'co-founder': 2,\n",
       " 'athlete': 9,\n",
       " 'mix': 13,\n",
       " 'biochemists': 2,\n",
       " 'commune': 7,\n",
       " 'off-limits': 2,\n",
       " \"'l\": 6,\n",
       " 'alloy': 1,\n",
       " 'rummy': 3,\n",
       " 'card': 63,\n",
       " 'cop': 5,\n",
       " 'autoimmune': 5,\n",
       " 'nations': 21,\n",
       " 'appalachian': 3,\n",
       " 'proceed': 2,\n",
       " 'insert': 1,\n",
       " 'spritz': 2,\n",
       " '1965': 16,\n",
       " 'hass': 9,\n",
       " '1939': 17,\n",
       " 'high-risk': 4,\n",
       " 'thomas': 15,\n",
       " 'confucius': 1,\n",
       " 'output': 3,\n",
       " 'enemies': 4,\n",
       " 'merrie': 3,\n",
       " 'scooby-doo': 4,\n",
       " 'fun': 5,\n",
       " 'one-fifth': 2,\n",
       " 'aurora': 1,\n",
       " 'simpler': 2,\n",
       " 'christina': 4,\n",
       " 'camera-ready': 3,\n",
       " 'lapwarmers': 3,\n",
       " 'text': 1,\n",
       " 'facts': 5,\n",
       " 'forehead': 1,\n",
       " 'steel': 13,\n",
       " 'seal': 4,\n",
       " 'soft': 46,\n",
       " 'boc': 1,\n",
       " 'participle': 4,\n",
       " 'band': 27,\n",
       " 'posh': 4,\n",
       " 'touch': 13,\n",
       " 'industrial': 5,\n",
       " 'corporate': 2,\n",
       " 'stradivarius': 2,\n",
       " 'tristan': 2,\n",
       " 'thousands': 1,\n",
       " 'distil': 1,\n",
       " 'data': 7,\n",
       " '&': 36,\n",
       " 'mrs.': 21,\n",
       " 'council': 19,\n",
       " 'teaspoon': 10,\n",
       " 'advantage': 3,\n",
       " '19': 17,\n",
       " 'united': 74,\n",
       " 'invent': 129,\n",
       " 'snowman': 5,\n",
       " 'jelly': 1,\n",
       " 'group': 67,\n",
       " 'folklore': 4,\n",
       " 'county': 34,\n",
       " 'freddie': 4,\n",
       " 'mayonnaise': 4,\n",
       " 'directions': 5,\n",
       " 'microverse': 1,\n",
       " 'disc': 11,\n",
       " 'dictator': 12,\n",
       " 'collins': 3,\n",
       " 'detect': 9,\n",
       " 'determine': 19,\n",
       " 'feature': 78,\n",
       " 'madeira': 1,\n",
       " 'anus': 3,\n",
       " 'benson': 2,\n",
       " 'lady': 15,\n",
       " 'mccarren': 13,\n",
       " 'separate': 10,\n",
       " 'hydroelectricity': 2,\n",
       " 'sea': 49,\n",
       " '985': 4,\n",
       " 'comes': 5,\n",
       " 'ancestral': 1,\n",
       " 'operation': 4,\n",
       " 'sutter': 2,\n",
       " 'home': 104,\n",
       " 'rico': 1,\n",
       " 'felt': 7,\n",
       " 'marco': 2,\n",
       " 'assassinate': 35,\n",
       " 'wizard': 2,\n",
       " 'eastern': 3,\n",
       " 'dog': 100,\n",
       " 'benjamin': 1,\n",
       " 'warfare': 4,\n",
       " 'tumble': 6,\n",
       " 'experts': 5,\n",
       " 'address': 66,\n",
       " 'victoria': 15,\n",
       " 'kythnos': 3,\n",
       " 'like': 70,\n",
       " 'garbage': 3,\n",
       " 'ultimate': 3,\n",
       " 'celestial': 2,\n",
       " 'arab': 4,\n",
       " 'kite': 3,\n",
       " 'll.m.': 4,\n",
       " 'iv': 2,\n",
       " 'prevail': 3,\n",
       " 'employment': 1,\n",
       " 'accuse': 1,\n",
       " 'writer': 24,\n",
       " 'valdez': 9,\n",
       " 'sex': 15,\n",
       " 'uprising': 2,\n",
       " 'post-its': 3,\n",
       " 'cover': 38,\n",
       " '13': 14,\n",
       " 'shirley': 10,\n",
       " 'angelica': 4,\n",
       " 'effective': 1,\n",
       " 'chinese': 30,\n",
       " 'alexandra': 7,\n",
       " 'skittle': 1,\n",
       " 'tons': 4,\n",
       " 'cavaliers': 1,\n",
       " 'killer': 13,\n",
       " 'beverly': 1,\n",
       " 'globe': 5,\n",
       " 'sleeping': 2,\n",
       " 'gaulle': 5,\n",
       " 'fahrenheit': 1,\n",
       " 'rarest': 5,\n",
       " 'james': 47,\n",
       " 'faber': 5,\n",
       " 'follow-up': 4,\n",
       " 'fourth': 10,\n",
       " 'huckleberry': 4,\n",
       " '1919': 1,\n",
       " 'gompers': 3,\n",
       " 'lol': 3,\n",
       " 'possum': 3,\n",
       " 'moran': 2,\n",
       " 'activity': 1,\n",
       " 'style': 8,\n",
       " 'york-style': 4,\n",
       " 'explosive': 4,\n",
       " 'these': 16,\n",
       " '468-pound': 5,\n",
       " 'crane': 3,\n",
       " 'vitamins': 2,\n",
       " 'prinze': 4,\n",
       " '199': 6,\n",
       " 'ybarra': 5,\n",
       " 'hajo': 5,\n",
       " '61': 2,\n",
       " 'scratch': 2,\n",
       " 'domestication': 2,\n",
       " 'yougurt': 2,\n",
       " 'tail': 10,\n",
       " 'fein': 13,\n",
       " 'die': 140,\n",
       " 'socrates': 1,\n",
       " 'amelia': 3,\n",
       " 'lata': 4,\n",
       " 'barbara': 5,\n",
       " 'bogart': 7,\n",
       " 'standard': 21,\n",
       " 'jolly': 3,\n",
       " 'secondary': 4,\n",
       " 'doughboys': 5,\n",
       " 'w': 5,\n",
       " 'magnetic': 2,\n",
       " 'monthly': 3,\n",
       " 'kickoff': 1,\n",
       " 'debt': 1,\n",
       " 'voter': 1,\n",
       " 'cola': 2,\n",
       " 'titanic': 15,\n",
       " 'spangled': 3,\n",
       " 'piano': 8,\n",
       " 'elm': 5,\n",
       " 'kubrick': 2,\n",
       " 'theme': 19,\n",
       " 'agreement': 3,\n",
       " 'association': 12,\n",
       " 'living': 1,\n",
       " 'babar': 5,\n",
       " '1984': 29,\n",
       " 'pothooks': 4,\n",
       " 'television': 39,\n",
       " 'recount': 3,\n",
       " 'chronic': 10,\n",
       " 'adventures': 5,\n",
       " 'square': 28,\n",
       " 'she': 21,\n",
       " 'chamber': 2,\n",
       " 'bph': 5,\n",
       " 'brandt': 1,\n",
       " 's&p': 1,\n",
       " 'slow': 5,\n",
       " 'divide': 5,\n",
       " 'belt': 5,\n",
       " 'recharge': 3,\n",
       " 'bullseye': 2,\n",
       " '48th': 2,\n",
       " 'breony': 3,\n",
       " 'captive': 1,\n",
       " 'majority': 5,\n",
       " '1781': 2,\n",
       " 'stay': 2,\n",
       " 'would': 72,\n",
       " 'botanical': 1,\n",
       " 'narragansett': 5,\n",
       " 'executor': 4,\n",
       " 'surge': 3,\n",
       " 'crayon': 1,\n",
       " 'paint': 68,\n",
       " 'almanac': 3,\n",
       " 'mob': 4,\n",
       " 'cold-water': 3,\n",
       " 'trivial': 6,\n",
       " 'sullivan': 8,\n",
       " 'antarctica': 5,\n",
       " 'everest': 8,\n",
       " 'mideast': 5,\n",
       " 'pail': 2,\n",
       " 'between': 171,\n",
       " 'bitmap': 3,\n",
       " 'gorbachev': 5,\n",
       " 'spears': 2,\n",
       " 'harness': 5,\n",
       " 'warm': 2,\n",
       " 'ankle': 2,\n",
       " 'frederick': 6,\n",
       " 'wenceslas': 5,\n",
       " 'russian': 56,\n",
       " 'shampoo': 6,\n",
       " 'different': 65,\n",
       " 's.': 1,\n",
       " 'comics': 16,\n",
       " '1957': 4,\n",
       " 'homer': 7,\n",
       " 'oj': 2,\n",
       " 'aviv': 1,\n",
       " 'supremacy': 4,\n",
       " 'denmark': 2,\n",
       " 'directly': 5,\n",
       " 'pecos': 5,\n",
       " 'weapon': 15,\n",
       " 'enemy': 4,\n",
       " 'budweiser': 4,\n",
       " 'saw': 36,\n",
       " '194': 2,\n",
       " 'dingoes': 1,\n",
       " 'mauritania': 4,\n",
       " 'havana': 3,\n",
       " 'caboose': 1,\n",
       " 'shalom': 4,\n",
       " 'trials': 9,\n",
       " 'about': 158,\n",
       " 'kay': 4,\n",
       " 'lament': 1,\n",
       " 'execution': 5,\n",
       " 'operant': 5,\n",
       " 'comedian': 29,\n",
       " 'wiener': 4,\n",
       " 'when': 527,\n",
       " 'van': 23,\n",
       " 'pineapple': 4,\n",
       " 'chiffons': 1,\n",
       " 'chapman': 5,\n",
       " 'succeed': 5,\n",
       " 'dickens': 16,\n",
       " 'fortifications': 1,\n",
       " 'philip': 5,\n",
       " 'reunite': 2,\n",
       " 'draw': 12,\n",
       " 'drew': 8,\n",
       " 'prix': 3,\n",
       " 'munich': 6,\n",
       " 'cozumel': 3,\n",
       " 'landmark': 8,\n",
       " 'sartorial': 2,\n",
       " 'obscene': 4,\n",
       " 'saltpeter': 8,\n",
       " 'credit': 18,\n",
       " 'easy': 4,\n",
       " 'steer': 1,\n",
       " 'bulgaricus': 5,\n",
       " 'notch': 4,\n",
       " 'raven': 4,\n",
       " 'star': 183,\n",
       " 'micronauts': 1,\n",
       " 'robb': 2,\n",
       " 'carrier': 5,\n",
       " 'fcc': 4,\n",
       " 'value': 12,\n",
       " 'whist': 1,\n",
       " 'wine': 27,\n",
       " 'airplanes': 3,\n",
       " 'dylan': 3,\n",
       " 'wiggins': 5,\n",
       " 'fly': 52,\n",
       " 'secret': 12,\n",
       " 'junk': 6,\n",
       " 'southdowns': 5,\n",
       " 'charcoal': 4,\n",
       " 'austerlitz': 2,\n",
       " 'wilding': 2,\n",
       " 'edison': 1,\n",
       " 'oscars': 7,\n",
       " 'hinduism': 2,\n",
       " 'chiang': 2,\n",
       " 'on-again': 1,\n",
       " 'scale': 3,\n",
       " 'non-fiction': 3,\n",
       " 'center': 48,\n",
       " 'bachelor': 3,\n",
       " 'league': 33,\n",
       " 'vice': 7,\n",
       " 'experience': 9,\n",
       " 'theories': 4,\n",
       " 'scandinavian': 5,\n",
       " 'u.s.a.': 7,\n",
       " 'fraction': 6,\n",
       " 'erect': 8,\n",
       " 'lehmann': 2,\n",
       " 'regulation': 5,\n",
       " 'odors': 4,\n",
       " 'plo': 9,\n",
       " 'christ': 7,\n",
       " 'li': 6,\n",
       " 'cabarnet': 3,\n",
       " '528': 1,\n",
       " 'trip': 13,\n",
       " 'gestapo': 4,\n",
       " 'leon': 5,\n",
       " 'donate': 11,\n",
       " 'arthur': 11,\n",
       " 'bible': 32,\n",
       " 'constantly': 1,\n",
       " 'freddy': 2,\n",
       " 'vatican': 12,\n",
       " 'freleng': 2,\n",
       " 'drought': 2,\n",
       " 'milky': 6,\n",
       " 'castor': 4,\n",
       " 'norway': 5,\n",
       " 'ostriches': 3,\n",
       " 'proliferation': 1,\n",
       " 'slam': 4,\n",
       " 'market': 33,\n",
       " 'diseases': 7,\n",
       " 'electronics': 4,\n",
       " 'pooh': 13,\n",
       " '46': 4,\n",
       " 'nafta': 5,\n",
       " 'johnny': 20,\n",
       " 'katharine': 4,\n",
       " 'roll': 20,\n",
       " 'maximum': 4,\n",
       " 'choose': 6,\n",
       " 'elicit': 5,\n",
       " '95': 1,\n",
       " 'surname': 9,\n",
       " 'exxon': 5,\n",
       " 'kings': 9,\n",
       " 'bake': 11,\n",
       " 'handheld': 9,\n",
       " 'biography': 5,\n",
       " 'bernardo': 1,\n",
       " 'esquire': 1,\n",
       " 'mint': 3,\n",
       " 'miles': 44,\n",
       " 'kurt': 2,\n",
       " 'felicity': 5,\n",
       " 'cpr': 5,\n",
       " 'question..': 4,\n",
       " 'auerstadt': 1,\n",
       " 'swimmer': 14,\n",
       " 'lawnmower': 2,\n",
       " 'prescription': 4,\n",
       " 'ago': 13,\n",
       " 'cigarette': 16,\n",
       " 'cascade': 5,\n",
       " 'sprawl': 5,\n",
       " 'plantation': 2,\n",
       " 'thank': 5,\n",
       " 'picture': 7,\n",
       " 'boy': 24,\n",
       " 'self-defense': 2,\n",
       " 'wasn': 1,\n",
       " 'frobisher': 2,\n",
       " 'destroyers': 1,\n",
       " 'constipation': 4,\n",
       " 'gemini': 2,\n",
       " 'milt': 2,\n",
       " 'sioux': 31,\n",
       " 'bra': 6,\n",
       " 'survivor': 1,\n",
       " 'feather': 5,\n",
       " 'bedroom': 3,\n",
       " 'germs': 1,\n",
       " 'preservation': 3,\n",
       " 'female': 40,\n",
       " 'tarantula': 4,\n",
       " 'smartnet': 2,\n",
       " 'kidnap': 10,\n",
       " 'winston': 5,\n",
       " 'dracula': 9,\n",
       " '188': 2,\n",
       " 'third': 12,\n",
       " 'tft': 1,\n",
       " 'drain': 1,\n",
       " 'zolotow': 2,\n",
       " 'tiger': 17,\n",
       " 'l.a.': 16,\n",
       " 'irish': 18,\n",
       " 'geoscientist': 2,\n",
       " 'horsemen': 1,\n",
       " 'light': 32,\n",
       " 'seriously': 4,\n",
       " 'surgeon': 3,\n",
       " 'secretary': 22,\n",
       " 'specifically': 3,\n",
       " 'rocky': 16,\n",
       " 'highest-paying': 3,\n",
       " 'fall': 8,\n",
       " 'bond': 26,\n",
       " 'saloons': 1,\n",
       " 'shakespeare': 24,\n",
       " 'la': 20,\n",
       " 'dannon': 2,\n",
       " 'continent': 22,\n",
       " 'commercials': 1,\n",
       " 'grimace': 3,\n",
       " 'puzzle': 4,\n",
       " 'within': 3,\n",
       " 'swear': 1,\n",
       " 'arma': 10,\n",
       " 'bjorn': 5,\n",
       " 'bullfighting': 3,\n",
       " 'sculpture': 9,\n",
       " 'spotlight': 5,\n",
       " 'finger': 19,\n",
       " 'pregnancy': 15,\n",
       " '1960': 12,\n",
       " 'streak': 1,\n",
       " 'saturday': 10,\n",
       " 'katy': 4,\n",
       " 'scientists': 6,\n",
       " \"'d\": 2,\n",
       " 'logo': 5,\n",
       " 'dry': 11,\n",
       " 'despondent': 4,\n",
       " 'football': 26,\n",
       " 'stole': 3,\n",
       " 'polyester': 2,\n",
       " 'sharp': 10,\n",
       " 'police': 14,\n",
       " 'jackie': 8,\n",
       " 'nantucket': 4,\n",
       " 'camden': 1,\n",
       " 'nns': 9,\n",
       " '8/28/1941': 4,\n",
       " 'pro': 15,\n",
       " 'vietnam': 26,\n",
       " 'iceland': 1,\n",
       " 'double-word-score': 5,\n",
       " 'englishman': 5,\n",
       " 'ferry': 3,\n",
       " 'vladimir': 5,\n",
       " 'appointments': 1,\n",
       " 'injectors': 5,\n",
       " 'coral': 1,\n",
       " 'stratton': 1,\n",
       " 'resignation': 4,\n",
       " 'hide': 5,\n",
       " 'svga': 3,\n",
       " 'relative': 6,\n",
       " 'ancient': 10,\n",
       " 'eenty': 5,\n",
       " 'condoms': 4,\n",
       " '239': 2,\n",
       " 'goldfus': 5,\n",
       " 'legendary': 5,\n",
       " 'pursuit': 6,\n",
       " 'pistol': 6,\n",
       " 'von': 6,\n",
       " 'opponents': 1,\n",
       " 'sales': 5,\n",
       " 'second': 43,\n",
       " 'duckling': 1,\n",
       " 'quarts': 5,\n",
       " 'fluorine': 4,\n",
       " 'moral': 6,\n",
       " 'yousuf': 5,\n",
       " 'realm': 1,\n",
       " 'dena': 5,\n",
       " 'snoogans': 5,\n",
       " 'organization': 34,\n",
       " 'glen': 4,\n",
       " 'contibution': 2,\n",
       " 'pride': 6,\n",
       " 'hydroelectric': 1,\n",
       " 'decree': 1,\n",
       " 'contributions': 4,\n",
       " 'est-ce': 2,\n",
       " 'prefix': 5,\n",
       " 'bombay': 10,\n",
       " 'career': 24,\n",
       " 'ursula': 4,\n",
       " 'decision': 1,\n",
       " 'waynesburg': 2,\n",
       " 'treehouse': 5,\n",
       " 'costliest': 5,\n",
       " 'president-to-be': 5,\n",
       " 'muppets': 17,\n",
       " 'ridder': 2,\n",
       " 'goals': 2,\n",
       " 'goes': 2,\n",
       " 'woodstock': 2,\n",
       " 'peters': 3,\n",
       " 'michaelangelo': 2,\n",
       " 'defense': 3,\n",
       " 'pampas': 1,\n",
       " 'marxism': 2,\n",
       " 'revival': 1,\n",
       " 'understand': 1,\n",
       " 'enzymes': 5,\n",
       " 'kisser': 3,\n",
       " 'cuckquean': 1,\n",
       " 'roads': 1,\n",
       " 'fortran': 3,\n",
       " 'nonaggression': 5,\n",
       " 'perfume': 5,\n",
       " 'cook': 9,\n",
       " 'bind': 3,\n",
       " 'desire': 3,\n",
       " 'check': 8,\n",
       " 'raise': 21,\n",
       " \"'hara\": 5,\n",
       " '195': 5,\n",
       " 'conversion': 3,\n",
       " 'ugly': 1,\n",
       " 'websites': 6,\n",
       " 'alexander': 3,\n",
       " 'rita': 5,\n",
       " 'aaa': 1,\n",
       " 'latent': 4,\n",
       " 'which': 439,\n",
       " 'less': 12,\n",
       " 'lift': 5,\n",
       " 'molybdenum': 5,\n",
       " 'natchitoches': 2,\n",
       " 'racoon': 5,\n",
       " 'lowlands': 1,\n",
       " 'canonize': 3,\n",
       " 'brilliant': 2,\n",
       " 'nba': 8,\n",
       " 'primitives': 4,\n",
       " 'maiden': 9,\n",
       " 'gunboat': 1,\n",
       " 'morning': 11,\n",
       " 'roast': 5,\n",
       " 'harlow': 5,\n",
       " 'guy': 9,\n",
       " 'hustle': 3,\n",
       " 'manager': 9,\n",
       " 'celebrity': 6,\n",
       " 'flush': 4,\n",
       " 'penguins': 2,\n",
       " 'xv': 2,\n",
       " 'biscuits': 4,\n",
       " 'alcoholic': 3,\n",
       " 'australian': 8,\n",
       " 'facility': 5,\n",
       " 'dragonflies': 1,\n",
       " 'laser': 7,\n",
       " 'intercourse': 13,\n",
       " 'booth': 5,\n",
       " 'inferno': 1,\n",
       " 'longest-lived': 5,\n",
       " 'start': 72,\n",
       " 'andy': 12,\n",
       " 'keyboard': 9,\n",
       " 'schematics': 1,\n",
       " 'twins': 4,\n",
       " 'to': 1692,\n",
       " 'splatterpunk': 2,\n",
       " 'jesus': 13,\n",
       " 'bloom': 6,\n",
       " 'proverb': 3,\n",
       " 'year..': 3,\n",
       " 'seccession': 1,\n",
       " 'braun': 5,\n",
       " 'porter': 3,\n",
       " 'verification': 1,\n",
       " 'earthquake': 1,\n",
       " 'groove': 6,\n",
       " 'jones': 14,\n",
       " '1935': 6,\n",
       " 'oath': 1,\n",
       " 'internet': 59,\n",
       " 'kippur': 1,\n",
       " 'wwi': 5,\n",
       " 'getting': 4,\n",
       " 'canon': 4,\n",
       " 'unfamiliar': 4,\n",
       " 'congressman': 13,\n",
       " 'snatch': 4,\n",
       " 'earthworms': 4,\n",
       " 'fill': 4,\n",
       " 'caucasian': 4,\n",
       " 'martha': 6,\n",
       " 'lund': 3,\n",
       " 'justice': 17,\n",
       " 'dysostosis': 2,\n",
       " 'clara': 4,\n",
       " 'equivalence': 4,\n",
       " 'go': 109,\n",
       " 'depression': 18,\n",
       " 'compound': 3,\n",
       " 'italians': 9,\n",
       " 'houseplants': 4,\n",
       " 'venice': 3,\n",
       " 'viii': 5,\n",
       " 'attire': 4,\n",
       " 'categorize': 1,\n",
       " 'awards': 6,\n",
       " 'spiritual': 4,\n",
       " 'abolitionists': 1,\n",
       " 'w.c.': 5,\n",
       " 'calleda': 2,\n",
       " 'district': 6,\n",
       " 'derive': 1,\n",
       " 'pecan': 5,\n",
       " 'cousin': 2,\n",
       " 'meet': 16,\n",
       " 'surface': 10,\n",
       " 'coddle': 1,\n",
       " 'barr': 4,\n",
       " 'differences': 7,\n",
       " 'luis': 5,\n",
       " 'rubens': 4,\n",
       " 'page': 23,\n",
       " 'service': 12,\n",
       " 'mystical': 4,\n",
       " '64': 3,\n",
       " 'achieve': 1,\n",
       " 'reflections': 4,\n",
       " 'qintex': 2,\n",
       " '16th-century': 4,\n",
       " 'wet': 3,\n",
       " 'creatures': 2,\n",
       " 'ray': 26,\n",
       " 'prisoner': 3,\n",
       " 'contact': 18,\n",
       " 'rule': 34,\n",
       " 'foot-pounds': 3,\n",
       " 'freeze': 11,\n",
       " 'vesuvius': 1,\n",
       " 'nightingale': 5,\n",
       " 'peller': 3,\n",
       " 'rockettes': 4,\n",
       " 'beryl': 3,\n",
       " 'smith': 2,\n",
       " 'florida': 16,\n",
       " 'manufacture': 18,\n",
       " 'invade': 8,\n",
       " 'larynx': 1,\n",
       " 'king': 75,\n",
       " 'berry': 1,\n",
       " 'carol': 6,\n",
       " 'hornby': 1,\n",
       " 'archenemy': 1,\n",
       " 'b12': 1,\n",
       " 'chronicles': 4,\n",
       " 'birthdate': 1,\n",
       " 'tristar': 8,\n",
       " 'allsburg': 2,\n",
       " '1990s': 5,\n",
       " 'dumas': 4,\n",
       " 'material': 4,\n",
       " 'oh': 4,\n",
       " 'copier': 5,\n",
       " 'terror': 2,\n",
       " 'dame': 5,\n",
       " 'present': 6,\n",
       " 'marvin': 5,\n",
       " 'claus': 9,\n",
       " 'whisker': 1,\n",
       " 'sonic': 1,\n",
       " 'five-zone': 2,\n",
       " '12601': 2,\n",
       " 'pollock': 10,\n",
       " 'rip': 5,\n",
       " 'river': 93,\n",
       " 'g.': 5,\n",
       " 'spritzer': 2,\n",
       " 'esperanto': 3,\n",
       " 'hiv': 9,\n",
       " 'substance': 15,\n",
       " 'calories': 13,\n",
       " 'lifelong': 3,\n",
       " 'melman': 2,\n",
       " 'tenderness': 1,\n",
       " 'distinguish': 6,\n",
       " 'horologist': 1,\n",
       " 'port': 8,\n",
       " 'optical': 3,\n",
       " 'dominos': 4,\n",
       " '48': 2,\n",
       " 'carl': 8,\n",
       " 'neither': 4,\n",
       " 'node': 1,\n",
       " 'acreage': 5,\n",
       " 'craig': 2,\n",
       " 'stevie': 5,\n",
       " 'pizarro': 1,\n",
       " 'pentagon': 1,\n",
       " 'elevation': 2,\n",
       " 'equal': 25,\n",
       " '1964': 8,\n",
       " 'marvel': 21,\n",
       " 'quilt': 1,\n",
       " 'noriega': 2,\n",
       " 'chocolate': 21,\n",
       " 'hairdryer': 1,\n",
       " 'rise': 7,\n",
       " 'scandal': 3,\n",
       " 'poems': 3,\n",
       " 'dialog': 1,\n",
       " 'original': 35,\n",
       " 'flying': 3,\n",
       " 'ping': 2,\n",
       " 'cloud': 16,\n",
       " 'gusto': 3,\n",
       " 'officer': 7,\n",
       " 'q': 3,\n",
       " 'aim': 1,\n",
       " 'columbia': 13,\n",
       " 'slightly': 5,\n",
       " 'crosstalk': 1,\n",
       " 'sauvignon': 3,\n",
       " 'giza': 1,\n",
       " 'brazil': 11,\n",
       " 'cone': 3,\n",
       " 'kalahari': 8,\n",
       " 'lack': 8,\n",
       " 'pasture': 4,\n",
       " 'toy': 15,\n",
       " 'summit': 3,\n",
       " 'gallon': 8,\n",
       " 'canada': 38,\n",
       " 'candlemas': 4,\n",
       " 'topophobic': 5,\n",
       " 'reaction': 2,\n",
       " 'interview': 5,\n",
       " 'alan': 3,\n",
       " 'dumbest': 2,\n",
       " 'crabgrass': 3,\n",
       " 'swimming': 5,\n",
       " 'mount': 25,\n",
       " 'gitchee': 2,\n",
       " 'paleozoic': 5,\n",
       " 'mauis': 1,\n",
       " 'spamming': 1,\n",
       " 'bebrenia': 3,\n",
       " 'redford': 5,\n",
       " 'lights': 2,\n",
       " 'astronaut': 14,\n",
       " 'softball': 7,\n",
       " 'favorite': 29,\n",
       " 'tournament': 8,\n",
       " 'kiss': 9,\n",
       " 'usenet': 2,\n",
       " '24-disc': 2,\n",
       " 'patent': 33,\n",
       " 'ms.': 4,\n",
       " 'trillion': 2,\n",
       " '1797-185': 9,\n",
       " 'prayer': 9,\n",
       " 'else': 5,\n",
       " 'underground': 1,\n",
       " 'balance': 10,\n",
       " 'populate': 4,\n",
       " 'untamed': 5,\n",
       " '1920s': 10,\n",
       " 'k': 13,\n",
       " 'theta': 4,\n",
       " 'plantar': 5,\n",
       " '3-pin': 2,\n",
       " 'preference': 2,\n",
       " 'nitrate': 4,\n",
       " 'horsepower': 6,\n",
       " 'recommend': 9,\n",
       " 'daycare': 10,\n",
       " 'do-right': 5,\n",
       " 'college': 67,\n",
       " 'sharon': 5,\n",
       " 'fruit-topped': 4,\n",
       " '219': 5,\n",
       " 'chemical': 33,\n",
       " 'benefit': 3,\n",
       " 'firemen': 4,\n",
       " 'electronic': 3,\n",
       " 'brenner': 3,\n",
       " 'proposition': 7,\n",
       " 'railways': 1,\n",
       " 'ten': 20,\n",
       " 'sigmund': 5,\n",
       " 'schwarzenegger': 5,\n",
       " 'gray': 6,\n",
       " 'subaru': 2,\n",
       " '1967': 16,\n",
       " 'beside': 2,\n",
       " 'action': 5,\n",
       " 'sunday': 5,\n",
       " 'finally': 3,\n",
       " 'magazine': 23,\n",
       " 'many': 894,\n",
       " 'reb': 2,\n",
       " 'info': 7,\n",
       " '33': 3,\n",
       " 'angel': 8,\n",
       " 'figure': 12,\n",
       " 'tokens': 5,\n",
       " 'telescope': 2,\n",
       " 'showtimes': 1,\n",
       " 'anthem': 8,\n",
       " 'blackberry': 1,\n",
       " 'ishmael': 3,\n",
       " 'ribavirin': 5,\n",
       " 'curies': 5,\n",
       " 'metric': 3,\n",
       " 'dig': 2,\n",
       " 'auto-commentary': 1,\n",
       " 'mouse': 14,\n",
       " 'pulaski': 5,\n",
       " 'siphnos': 3,\n",
       " 'frog': 6,\n",
       " '1669': 1,\n",
       " 'ford': 17,\n",
       " 'planet': 17,\n",
       " 'bibliographies': 4,\n",
       " 'provo': 4,\n",
       " '49': 9,\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('become', 142),\n",
       " ('day', 141),\n",
       " ('die', 140),\n",
       " ('stand', 140),\n",
       " ('tv', 137),\n",
       " ('your', 137),\n",
       " ('or', 137),\n",
       " ('man', 136),\n",
       " ('show', 131),\n",
       " ('one', 130)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Less commons words in your vocabulary\n",
    "Counter(vocabulary).most_common(nb_input-1)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary contains 100 words.\n"
     ]
    }
   ],
   "source": [
    "word_list = list([x[0] for x in Counter(vocabulary).most_common(nb_input-1)])\n",
    "\n",
    "# We add the unk word for future purpose.\n",
    "word_list.append('<unk>')\n",
    "words_array = np.array(word_list)\n",
    "print(\"Vocabulary contains\", len(words_array), \"words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Integer encoding with OneHotEncoder\n",
    "words_tre = words_array.reshape(len(words_array),1)\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "onehot_encoded = one_hot_encoder.fit_transform(words_tre)\n",
    "print(onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionnary of word and its one hot array\n",
    "words_onehoted = {}\n",
    "for i in range(0, len(words_array)):\n",
    "    words_onehoted[word_list[i]] = onehot_encoded[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the corresponding one hot list for a word.\n",
    "def get_onehot_word(word):\n",
    "    if word in words_onehoted:\n",
    "        return list(words_onehoted[word])\n",
    "    else:\n",
    "        return list(words_onehoted['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh = get_onehot_word('<unk>')\n",
    "one = oh.index(1.0)\n",
    "one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing if an unknown word is transformed into a <unk>\n",
    "get_onehot_word('obviously_an_unknown_word').index(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot categories\n",
    "\n",
    "categories_onehoted = {}\n",
    "categories_onehoted['ABBR'] = [1, 0, 0, 0, 0, 0] # Abbreviation\n",
    "categories_onehoted['ENTY'] = [0, 1, 0, 0, 0, 0] # Entity\n",
    "categories_onehoted['DESC'] = [0, 0, 1, 0, 0, 0] # Description\n",
    "categories_onehoted['HUM']  = [0, 0, 0, 1, 0, 0] # Human\n",
    "categories_onehoted['LOC']  = [0, 0, 0, 0, 1, 0] # Location\n",
    "categories_onehoted['NUM']  = [0, 0, 0, 0, 0, 1] # Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the corresponding one hot list for a category.\n",
    "def get_onehot_category(category):\n",
    "    return categories_onehoted[category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh = get_onehot_category('HUM')\n",
    "one = oh.index(1.0)\n",
    "one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.22 s, sys: 108 ms, total: 2.33 s\n",
      "Wall time: 2.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Creating training set\n",
    "\n",
    "batch_data = []\n",
    "for num_question in range(len(questions)):\n",
    "    # Construction of question_onehot list.\n",
    "    question_onehot = [get_onehot_word(word) for word in questions[num_question]]\n",
    "    \n",
    "    # Construction of category_onehot.\n",
    "    category = labels[num_question].partition(':')[0]\n",
    "    category_onehot = get_onehot_category(category)\n",
    "    batch_data.append([tensor([question_onehot]), tensor([category_onehot])])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 64 ms, sys: 4 ms, total: 68 ms\n",
      "Wall time: 64.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Creating test set\n",
    "\n",
    "batch_data_test = []\n",
    "for num_question in range(len(questions_test)):\n",
    "    \n",
    "    # Construction of question_onehot list.\n",
    "    question_onehot = [get_onehot_word(word) for word in questions[num_question]]\n",
    "    \n",
    "    # Construction of category_onehot.\n",
    "    category = labels_test[num_question].partition(':')[0]\n",
    "    category_onehot = get_onehot_category(category)\n",
    "    batch_data_test.append([tensor([question_onehot]), tensor([category_onehot])])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN implementation\n",
    "Using ReLU, and CrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, nb_inputs, nb_layers, nb_neurons, nb_outputs, learning_rate):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        # Applying RNN layer, and softmax then\n",
    "        self.rnn = nn.RNN(input_size=nb_inputs, num_layers=nb_layers,\n",
    "                   hidden_size=nb_neurons, dropout=0.5, batch_first=True, nonlinearity='relu')\n",
    "        self.inter = nn.Linear(nb_neurons, nb_outputs)\n",
    "        self.sm = nn.Softmax(dim=2)\n",
    "        \n",
    "        # Other usefull variables here\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        self.input_dim = nb_inputs\n",
    "        self.output_dim = nb_output\n",
    "        self.nb_layers = nb_layers\n",
    "        self.nb_neurons = nb_neurons\n",
    "        #self.synapses = Variable(torch.zeros(self.nb_layers, 1, self.nb_neurons))\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        h0 = Variable(torch.zeros(self.nb_layers, inputs.size(0), self.nb_neurons))\n",
    "        if use_cuda:\n",
    "            h0 = h0.to(\"cuda\")\n",
    "        \n",
    "        x, hn = self.rnn(inputs, h0)\n",
    "        \n",
    "        x = self.inter(x)\n",
    "        x = nn.functional.softmax(x, dim=2)\n",
    "        return x\n",
    "\n",
    "# End of the class RNN\n",
    "\n",
    "# Now let's define learn(), which learn a RNN some data\n",
    "def learn(rnn, batch_list, num_epochs=1):\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if use_cuda:\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "        rnn.cuda(device)\n",
    "    \n",
    "    # Preparing\n",
    "    rnn.train()\n",
    "    losses = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Shuffling batch_list\n",
    "    shuffle(batch_list)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, (data, target) in enumerate(batch_list):\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            #data, target = Variable(data), Variable(target)\n",
    "            \n",
    "            output = rnn(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            losses.append(loss.data.item())\n",
    "\n",
    "            rnn.optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "            rnn.optimizer.step()\n",
    "            \n",
    "            # Print the progress\n",
    "            if batch_idx % 100 == 0 or batch_idx % 100 == 1 or batch_idx == len(batch_list)-1:\n",
    "                print('\\r Train Epoch: {} [{}/{} ({:.0f}%)]\\t Loss: {:.6f}'.format(\n",
    "                        epoch, \n",
    "                        (batch_idx+1) * len(data), \n",
    "                        len(batch_list),\n",
    "                        100. * (batch_idx+1) / len(batch_list), \n",
    "                        loss.data.item()), \n",
    "                        end='')\n",
    "        print()\n",
    "        \n",
    "    # Return losses list, you can print them later if you want\n",
    "    return losses\n",
    "\n",
    "\n",
    "# return (rightAnswer, ignored, falseAnswer)\n",
    "def getEfficience(rnn, batch_list, tresh=0) :\n",
    "    rightAnswer = 0\n",
    "    ignored = 0\n",
    "    falseAnswer = 0\n",
    "    \n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    for (data, target) in batch_list :\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        predicted = rnn(data).detach().cpu().numpy()[-1][-1]\n",
    "        #print(\"predicted: \"+str(np.argmax(predicted)))\n",
    "        #print(\"target: \"+str(np.argmax(target.detach().cpu().numpy()[-1])))\n",
    "        if max(predicted) < tresh :\n",
    "            ignored += 1\n",
    "        else:\n",
    "            if np.argmax(predicted) == np.argmax(target.detach().cpu().numpy()[-1]):\n",
    "                rightAnswer += 1\n",
    "            else:\n",
    "                falseAnswer += 1\n",
    "    return (rightAnswer, ignored, falseAnswer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/info/etu/m2/i140302/venv/lib/python3.5/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Epoch: 0 [15452/15452 (100%)]\t Loss: 2.213928\n",
      " Train Epoch: 1 [15452/15452 (100%)]\t Loss: 2.214175\n",
      " Train Epoch: 2 [15452/15452 (100%)]\t Loss: 2.214204\n",
      " Train Epoch: 3 [15452/15452 (100%)]\t Loss: 2.214206\n",
      " Train Epoch: 4 [15452/15452 (100%)]\t Loss: 2.214208\n",
      "Done :)\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(nb_inputs = nb_input, nb_layers=nb_hidd_lay,\n",
    "          nb_neurons=hidden_size, nb_outputs=nb_output, learning_rate=lr)\n",
    "if use_cuda:\n",
    "    rnn = rnn.to(\"cuda\")\n",
    "losses = learn(rnn, batch_data, nb_epochs)\n",
    "print(\"Done :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8bbc11a6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046587ccaafa46f7bceae6d356ffd20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=51, description='smooth', max=201, min=5, step=2), Output()), _dom_class…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "x = np.linspace(0, len(losses), len(losses))\n",
    "fig = plt.figure(figsize=(13, 8)) \n",
    "ax = fig.add_subplot(1,1,1)\n",
    "cnn_line, = ax.plot(x, losses)\n",
    "\n",
    "def update_losses(smooth=51):\n",
    "    cnn_line.set_ydata(savgol_filter(losses, smooth, 3))\n",
    "    fig.canvas.draw()\n",
    "\n",
    "interact(update_losses, smooth=(5, 201, 2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations! On the training set:\n",
      "Corrects: 23.472689619466735%\n",
      "False:    76.52731038053327%\n",
      "\n",
      "Congratulations! On the test set:\n",
      "Corrects: 18.8%\n",
      "False:    81.2%\n",
      "\n",
      "A présent, tu peux copier-coller ça dans le doc sur le drive :)\n",
      "100\t0.005\t5\t1\t1\t\t18.8%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "final_results = getEfficience(rnn, batch_data)\n",
    "total = sum(final_results)\n",
    "\n",
    "correct = final_results[0]/total*100\n",
    "ignored = final_results[1]/total*100\n",
    "false = final_results[2]/total*100\n",
    "\n",
    "\n",
    "\n",
    "print(\"Congratulations! On the training set:\")\n",
    "print(\"Corrects: \" + str(correct) + \"%\")\n",
    "#print(\"Ignored:  \" + str(ignored) + \"%\")\n",
    "print(\"False:    \" + str(false) + \"%\")\n",
    "print()\n",
    "\n",
    "final_results = getEfficience(rnn, batch_data_test)\n",
    "total = sum(final_results)\n",
    "\n",
    "correct = final_results[0]/total*100\n",
    "ignored = final_results[1]/total*100\n",
    "false = final_results[2]/total*100\n",
    "\n",
    "\n",
    "\n",
    "print(\"Congratulations! On the test set:\")\n",
    "print(\"Corrects: \" + str(correct) + \"%\")\n",
    "#print(\"Ignored:  \" + str(ignored) + \"%\")\n",
    "print(\"False:    \" + str(false) + \"%\")\n",
    "\n",
    "print()\n",
    "print(\"A présent, tu peux copier-coller ça dans le doc sur le drive :)\")\n",
    "print(str(nb_input)+\"\\t\"+str(lr)+\"\\t\"+str(nb_epochs)+\"\\t\"+str(nb_hidd_lay)+\"\\t\"+str(hidden_size)+\"\\t\\t\"+str(correct)+\"%\")\n",
    "print()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
